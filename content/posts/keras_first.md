---
title: Keras ç®€å•å°è¯•
author: pigLoveRabbit
tags:
  - Keras
categories:
  - æ·±åº¦å­¦ä¹ 
date: 2024-10-25 19:00:00
---
![Keras](/images/my-keras.png)
<!-- more -->
## å®‰è£…Keras
Keras 2 æ˜¯ä¸€ä¸ªè¾ƒæ—§çš„ç‰ˆæœ¬ï¼ˆæœ€æ–°ä¸»ç‰ˆæœ¬ä¸º Keras 3ï¼Œä½†è®¸å¤šç”¨æˆ·ä»åœ¨ä½¿ç”¨ Keras 2.xï¼Œå°¤å…¶æ˜¯é…åˆ TensorFlow 1.x æˆ– 2.x æ—©æœŸç‰ˆæœ¬ï¼‰ã€‚  
è£…TensorFlow 2.15çš„æ—¶å€™ï¼ŒKeras 2è‡ªåŠ¨å°±å¸¦ä¸Šäº†ã€‚
```
pip install tensorflow==2.15.0
```

## ä¸€ä¸ªdemo
```Python
import tensorflow as tf
import keras

print(f"TensorFlowç‰ˆæœ¬: {tf.__version__}")
print(f"Kerasç‰ˆæœ¬: {keras.__version__}")

# åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡å‹
model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    keras.layers.Dense(10, activation='softmax')
])

print("æ¨¡å‹åˆ›å»ºæˆåŠŸï¼")
```
[è§†é¢‘è¯¾ç¨‹](https://www.bilibili.com/video/BV1Bp4y1D7YL/?p=8)  

## å®ç°çº¿æ€§å›å½’
```python
import keras
import numpy as np
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
# SequentialæŒ‰é¡ºåºæ„æˆçš„æ¨¡å‹
from keras.models import Sequential
# Denseå…¨è¿æ¥å±‚
from keras.layers import Dense

# ä½¿ç”¨numpyç”Ÿæˆ100ä¸ªéšæœºç‚¹
x_data = np.random.rand(100)
noise = np.random.normal(0, 0.01, x_data.shape)
y_data = x_data*0.1 + 0.2 + noise


# æ„å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹
model= Sequential()
# åœ¨æ¨¡å‹ä¸­æ·»åŠ ä¸€ä¸ªå…¨è¿æ¥å±‚
model.add(Dense(units=1, input_dim=1))
# sgdï¼šStochasticgradientdescentï¼Œéšæœºæ¢¯åº¦ä¸‹é™æ³•
# mseï¼šMean Squared Errorï¼Œå‡æ–¹è¯¯å·®
model.compile(optimizer='sgd', loss='mse')

# è®­ç»ƒ3001ä¸ªæ‰¹æ¬¡
for step in range(3001):
    # æ¯æ¬¡è®­ç»ƒä¸€ä¸ªæ‰¹æ¬¡
    cost = model.train_on_batch(x_data, y_data)
    # æ¯500ä¸ªbatchæ‰“å°ä¸€æ¬¡costå€¼
    if step % 500 == 0:
        print('cost:', cost)
# æ‰“å°æƒå€¼å’Œåç½®å€¼
W, b = model. layers[0].get_weights()
print('w:', W, 'b:', b)
# x_dataè¾“å…¥ç½‘ç»œä¸­ï¼Œå¾—åˆ°é¢„æµ‹å€¼y_pred
y_pred = model.predict(x_data)

# æ˜¾ç¤ºéšæœºç‚¹
plt.scatter(x_data, y_data)
# æ˜¾ç¤ºé¢„æµ‹ç»“æœ
plt.plot(x_data, y_pred, 'r-', lw=3) # y_predçš„shapeæ˜¯(100, 1)ï¼Œä½†plot() å‡½æ•°å¯ä»¥è‡ªåŠ¨å¤„ç†è¿™ç§å½¢çŠ¶å·®å¼‚
plt.show()
```

## éçº¿æ€§å›å½’
```Python
import keras
import numpy as np
import matplotlib
matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt
# SequentialæŒ‰é¡ºåºæ„æˆçš„æ¨¡å‹
from keras.models import Sequential
# Denseå…¨è¿æ¥å±‚
from keras.layers import Dense, Activation
from keras.optimizers import SGD, Adam

#ä½¿ç”¨numpyç”Ÿæˆ200ä¸ªéšæœºç‚¹
x_data = np.linspace(-0.5, 0.5, 200)
noise = np.random.normal(0, 0.02, x_data.shape)
y_data = np.square(x_data) + noise

#æ„ç¡¬ä¸€ä¸ªé¡ºåºæ¨¡å‹
model=Sequential()
#åœ¨æ¨¡å‹ä¸­æ·»åŠ ä¸€ä¸ªå…¨è¿æ¥å±‚
# æ„å»ºæ¨¡å‹ - ä¿®æ­£ç‰ˆæœ¬
model = Sequential()
# éšè—å±‚ä½¿ç”¨tanhæˆ–reluéƒ½å¯ä»¥ï¼Œä½†éœ€è¦åˆé€‚çš„åˆå§‹åŒ–
model.add(Dense(units=64, input_dim=1, activation='relu', kernel_initializer='he_normal'))
model.add(Dense(units=32, activation='relu', kernel_initializer='he_normal'))
# é‡è¦ï¼šè¾“å‡ºå±‚ä¸è¦ä½¿ç”¨æ¿€æ´»å‡½æ•°ï¼ˆæˆ–ç”¨çº¿æ€§æ¿€æ´»ï¼‰ç”¨äºå›å½’é—®é¢˜
model.add(Dense(units=1))  # é»˜è®¤å°±æ˜¯çº¿æ€§æ¿€æ´»

# ä½¿ç”¨æ›´ç¨³å®šçš„ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡è°ƒå°
optimizer = Adam(learning_rate=0.01)  # æˆ–è€… SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=optimizer, loss='mse')

#è®­ç»ƒ3001ä¸ªæ‰¹æ¬¡
for step in range(3001):
    #æ¯æ¬¡è®­ç»ƒä¸€ä¸ªæ‰¹æ¬¡
    cost = model.train_on_batch(x_data, y_data)
    #æ¯500ä¸ªbatchæ‰“å°ä¸€æ¬¡costå€¼
    if step % 500==0:
        print('cost:', cost)


#model.fit(x_data, y_data, epochs=300, batch_size=32, verbose=1)
        
#x_dataè¾“å…¥ç½‘ç»œä¸­ï¼Œå¾—åˆ°é¢„æµ‹å€¼y_pred
y_pred = model.predict(x_data)
#æ˜¾ç¤ºéšæœºç‚¹
plt.scatter(x_data, y_data)
#æ˜¾ç¤ºé¢„æµ‹ç»“æœ
plt.plot(x_data, y_pred, 'r-', lw=3)
plt.show()
```
### ğŸ”§ å…¶ä»–æ”¹è¿›å»ºè®®

1. **å­¦ä¹ ç‡å¤ªé«˜**ï¼š`SGD(lr=0.3)` å¯¹äºè¿™ç§å°è§„æ¨¡é—®é¢˜å¯èƒ½å¤ªå¤§ï¼Œå®¹æ˜“éœ‡è¡ã€‚å»ºè®®ç”¨ `0.01` æˆ–ä½¿ç”¨ `Adam` ä¼˜åŒ–å™¨ï¼ˆè‡ªé€‚åº”å­¦ä¹ ç‡ï¼‰ã€‚
2. **å¢åŠ è®­ç»ƒè½®æ•°æˆ–ä½¿ç”¨ `fit()`**ï¼š`train_on_batch` è™½ç„¶çµæ´»ï¼Œä½†ä¸å¦‚ `model.fit(x_data, y_data, epochs=3000, verbose=1)` æ–¹ä¾¿ï¼Œä¸”é»˜è®¤ä¼šåšæ›´å¥½çš„å†…éƒ¨å¤„ç†ã€‚
3. **éšè—å±‚æ¿€æ´»å‡½æ•°æ²¡é—®é¢˜**ï¼š`relu` åœ¨éšè—å±‚æ˜¯å¯ä»¥çš„ï¼Œä¹Ÿå¯ä»¥è¯•è¯• `tanh`ï¼ˆå¯¹ç§°ï¼Œé€‚åˆæ‹Ÿåˆ xÂ² è¿™ç§å¯¹ç§°å‡½æ•°ï¼‰ã€‚


## æ•°å­—è¯†åˆ«
6wå¼ å›¾ç‰‡çš„æ•°æ®é›†
```
import os
from keras.datasets import mnist
from keras import utils
from keras.optimizers import SGD
from keras.models import Sequential
from keras.layers import Dense
import numpy as np

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
# è½½å…¥æ•°æ®
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# (60000,28,28)
print('x_shape:', x_train.shape)
# (60000)
print('y_shape', y_train.shape)
# (60000,28,28)->(60000,784)
x_train = x_train.reshape(x_train.shape[0], -1)/255.0
x_test = x_test.reshape(x_test.shape[0], -1)/255.0
# æ¢one hotæ ¼å¼
y_train = utils.to_categorical(y_train, num_classes=10)
y_test = utils.to_categorical(y_test, num_classes=10)

# åˆ›å»ºæ¨¡å‹ï¼Œè¾“å…¥784ä¸ªç¥ç»å…ƒï¼Œè¾“å‡º10ä¸ªç¥ç»å…ƒ
model = Sequential([
    Dense(units=10, input_dim=784, bias_initializer='one', activation='softmax')
])
# å®šä¹‰ä¼˜åŒ–å™¨
sgd = SGD(learning_rate=0.2)
# è®¾ç½®loss functionï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­å‡†ç¡®ç‡
model.compile(optimizer = sgd, loss='mse', metrics=['accuracy'])
# è®­ç»ƒæ¨¡å‹ï¼Œ6wå¼ å›¾æ¯æ¬¡æ‹¿32å¼ è®­ç»ƒ
model.fit(x_train, y_train, batch_size=32, epochs=10)
# è¯„ä¼°æ¨¡å‹
loss,accuracy = model.evaluate(x_test, y_test)
print('\ntest loss', loss)
print('accuracy', accuracy)
```
